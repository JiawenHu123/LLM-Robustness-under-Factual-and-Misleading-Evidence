import json
import re
from transformers import pipeline
from collections import defaultdict

class SupportValidator:
    def __init__(self):
        # åˆå§‹åŒ–NLIæ¨¡å‹
        try:
            self.nli_pipeline = pipeline(
                "text-classification", 
                model="roberta-large-mnli",
                device=-1
            )
            self.nli_available = True
            print("NLIæ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"NLIæ¨¡å‹åŠ è½½å¤±è´¥: {e}ï¼Œå°†ä»…ä½¿ç”¨åŸºç¡€éªŒè¯")
            self.nli_available = False
    
    def extract_entities(self, text):
        """æå–æ–‡æœ¬ä¸­çš„å…³é”®å®ä½“"""
        entities = []
        
        # æå–å›½å®¶å
        countries = ['UK', 'United Kingdom', 'USA', 'United States', 'America', 'France', 
                    'Japan', 'Canada', 'Australia', 'New Zealand', 'Germany', 'Italy',
                    'Spain', 'South Korea', 'Singapore', 'Netherlands', 'Sweden', 'China',
                    'Mexico', 'India', 'Cambodia', 'Myanmar']
        
        for country in countries:
            if country.lower() in text.lower():
                entities.append(country)
        
        # æå–å…¶ä»–å¤§å†™ä¸“æœ‰åè¯
        words = re.findall(r'\b[A-Z][a-z]+\b', text)
        entities.extend([word for word in words if len(word) > 2])
        
        return list(set(entities))
    
    def check_logical_consistency(self, correct_answer, support_text):
        """æ£€æŸ¥supportä¸correct answerçš„é€»è¾‘ä¸€è‡´æ€§ - æ›´å®½æ¾çš„ç‰ˆæœ¬"""
        answer_lower = correct_answer.lower()
        support_lower = support_text.lower()
        
        # æ£€æŸ¥æ˜æ˜¾çš„é€»è¾‘çŸ›ç›¾
        contradiction_pairs = [
            ('is true', 'is false'), 
            ('is correct', 'is incorrect'),
            ('can', 'cannot'),
            ('cannot', 'can'),
        ]
        
        for term1, term2 in contradiction_pairs:
            if term1 in answer_lower and term2 in support_lower:
                return False, f"æ˜æ˜¾çŸ›ç›¾: '{term1}'åœ¨ç­”æ¡ˆä¸­ä½†'{term2}'åœ¨supportä¸­"
            if term2 in answer_lower and term1 in support_lower:
                return False, f"æ˜æ˜¾çŸ›ç›¾: '{term2}'åœ¨ç­”æ¡ˆä¸­ä½†'{term1}'åœ¨supportä¸­"
        
        # å¯¹äºç›¸å¯¹æ€§è¯æ±‡ï¼ˆhigher/lower, more/lessï¼‰éœ€è¦æ›´è°¨æ…çš„åˆ¤æ–­
        relative_pairs = [('higher', 'lower'), ('lower', 'higher'), ('more', 'less'), ('less', 'more')]
        for term1, term2 in relative_pairs:
            if term1 in answer_lower and term2 in support_lower:
                # æ£€æŸ¥æ˜¯å¦åœ¨åŒä¸€ä¸ªä¸Šä¸‹æ–‡ä¸­
                context_words = ['bmi', 'income', 'education', 'hours', 'work', 'rich']
                has_context = any(ctx in answer_lower or ctx in support_lower for ctx in context_words)
                if has_context:
                    return False, f"ç›¸å¯¹æ€§çŸ›ç›¾: '{term1}'åœ¨ç­”æ¡ˆä¸­ä½†'{term2}'åœ¨supportä¸­"
        
        return True, "é€»è¾‘ä¸€è‡´"
    
    def contains_contradiction(self, support_text):
        """æ£€æŸ¥supportå†…éƒ¨æ˜¯å¦å­˜åœ¨çŸ›ç›¾ - æ›´å®½æ¾çš„ç‰ˆæœ¬"""
        sentences = re.split(r'[.!?]', support_text)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        if len(sentences) < 2:
            return False, "å¥å­å¤ªå°‘ï¼Œæ— æ³•æ£€æµ‹å†…éƒ¨çŸ›ç›¾"
        
        # åªæ£€æŸ¥æ˜æ˜¾çš„å†…éƒ¨çŸ›ç›¾
        for i in range(len(sentences)-1):
            sent1 = sentences[i].lower()
            sent2 = sentences[i+1].lower()
            
            opposite_pairs = [
                ('is true', 'is false'), 
                ('is correct', 'is incorrect'),
                ('supports', 'contradicts'),
                ('can', 'cannot'),
            ]
            
            for pair1, pair2 in opposite_pairs:
                if (pair1 in sent1 and pair2 in sent2) or (pair2 in sent1 and pair1 in sent2):
                    return True, f"å†…éƒ¨çŸ›ç›¾: å¥å­{i+1}è¯´'{pair1}'ä½†å¥å­{i+2}è¯´'{pair2}'"
        
        return False, "æ— å†…éƒ¨çŸ›ç›¾"
    
    def validate_support_basic(self, item):
        """åŸºç¡€è§„åˆ™éªŒè¯ - æ›´å®½æ¾çš„ç‰ˆæœ¬"""
        issues = []
        detailed_issues = []
        
        correct_answer = item.get('answer_theme', '')
        support_text = item.get('support', {}).get('text', '')
        
        if not correct_answer or not support_text:
            issues.append("ç¼ºå°‘answer_themeæˆ–support.text")
            detailed_issues.append("ç¼ºå°‘answer_themeæˆ–support.text")
            return False, issues, detailed_issues
        
        # 1. æ£€æŸ¥supportæ˜¯å¦åŒ…å«correct answerä¸­çš„å…³é”®å®ä½“ - æ›´å®½æ¾
        key_entities = self.extract_entities(correct_answer)
        missing_entities = []
        
        for entity in key_entities:
            # å…è®¸å®ä½“æœ‰å˜ä½“å½¢å¼
            entity_variants = [entity, entity.lower(), entity.upper()]
            if not any(variant in support_text for variant in entity_variants):
                # å¯¹äºå¸¸è§ç¼©å†™ä¹Ÿæ£€æŸ¥
                if entity == 'USA' and 'united states' not in support_text.lower():
                    missing_entities.append(entity)
                elif entity == 'UK' and 'united kingdom' not in support_text.lower():
                    missing_entities.append(entity)
                else:
                    missing_entities.append(entity)
        
        if missing_entities:
            issues.append(f"å…³é”®å®ä½“ç¼ºå¤±: {', '.join(missing_entities)}")
            detailed_issues.append(f"å…³é”®å®ä½“ç¼ºå¤±: {', '.join(missing_entities)}")
        
        # 2. æ£€æŸ¥supportæ˜¯å¦ä¸correct answeré€»è¾‘ä¸€è‡´
        logic_consistent, logic_message = self.check_logical_consistency(correct_answer, support_text)
        if not logic_consistent:
            issues.append("supportä¸correct answeré€»è¾‘ä¸ä¸€è‡´")
            detailed_issues.append(f"é€»è¾‘ä¸ä¸€è‡´: {logic_message}")
        
        # 3. æ£€æŸ¥supportæ˜¯å¦åŒ…å«çŸ›ç›¾é™ˆè¿°
        has_contradiction, contradiction_message = self.contains_contradiction(support_text)
        if has_contradiction:
            issues.append("supportå†…éƒ¨å­˜åœ¨çŸ›ç›¾")
            detailed_issues.append(f"å†…éƒ¨çŸ›ç›¾: {contradiction_message}")
        
        # 4. æ£€æŸ¥supportæ˜¯å¦è¿‡äºç®€å• - æ›´å®½æ¾çš„æ ‡å‡†
        sentences = re.split(r'[.!?]', support_text)
        meaningful_sentences = [s.strip() for s in sentences if len(s.strip()) > 5]  # é™ä½é•¿åº¦è¦æ±‚
        if len(meaningful_sentences) < 1:  # è‡³å°‘1ä¸ªæœ‰æ„ä¹‰çš„å¥å­
            issues.append("supportå†…å®¹è¿‡äºç®€å•")
            detailed_issues.append(f"supportå†…å®¹è¿‡äºç®€å•: åªæœ‰{len(meaningful_sentences)}ä¸ªæœ‰æ„ä¹‰çš„å¥å­")
        
        return len(issues) == 0, issues, detailed_issues
    
    def validate_support_with_nli(self, item):
        """ä½¿ç”¨NLIæ¨¡å‹éªŒè¯supportæ˜¯å¦æ”¯æŒcorrect answer - æ›´å®½æ¾çš„ç‰ˆæœ¬"""
        if not self.nli_available:
            return True, "NLIä¸å¯ç”¨ï¼Œè·³è¿‡éªŒè¯"
        
        premise = item.get('support', {}).get('text', '')
        hypothesis = item.get('answer_theme', '')
        
        if not premise or not hypothesis:
            return False, "å‰ææˆ–å‡è®¾ä¸ºç©º"
        
        try:
            # æ„å»ºNLIè¾“å…¥
            result = self.nli_pipeline(f"{premise} [SEP] {hypothesis}")
            
            label = result[0]['label']
            score = result[0]['score']
            
            # æ›´å®½æ¾çš„é˜ˆå€¼è®¾ç½®
            if label == 'ENTAILMENT' and score > 0.4:  # é™ä½é˜ˆå€¼åˆ°0.4
                return True, f"NLIéªŒè¯é€šè¿‡: {label} (ç½®ä¿¡åº¦: {score:.3f})"
            elif label == 'NEUTRAL' and score > 0.6:   # NEUTRALä¹Ÿæ¥å—ï¼Œå¦‚æœç½®ä¿¡åº¦é«˜
                return True, f"NLIéªŒè¯é€šè¿‡: {label} (ç½®ä¿¡åº¦: {score:.3f})"
            else:
                return False, f"NLIéªŒè¯å¤±è´¥: {label} (ç½®ä¿¡åº¦: {score:.3f})"
                
        except Exception as e:
            return False, f"NLIéªŒè¯å‡ºé”™: {e}"
    
    def debug_nli_analysis(self, item):
        """è°ƒè¯•NLIåˆ†æï¼Œæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯"""
        if not self.nli_available:
            return "NLIä¸å¯ç”¨"
        
        premise = item.get('support', {}).get('text', '')
        hypothesis = item.get('answer_theme', '')
        
        result = self.nli_pipeline(f"{premise} [SEP] {hypothesis}")
        
        debug_info = {
            'premise_length': len(premise),
            'hypothesis_length': len(hypothesis),
            'premise_preview': premise[:100] + "..." if len(premise) > 100 else premise,
            'hypothesis_preview': hypothesis[:100] + "..." if len(hypothesis) > 100 else hypothesis,
            'nli_result': result[0]
        }
        
        return debug_info
    
    def comprehensive_validation(self, items):
        """ç»¼åˆéªŒè¯æµæ°´çº¿ - æ›´å®½æ¾çš„ç‰ˆæœ¬"""
        validation_results = {
            'passed': [],
            'failed_basic': [],
            'failed_nli': [], 
            'failed_both': [],
            'all_failed_details': [],
            'debug_info': []  # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        }
        
        print(f"å¼€å§‹éªŒè¯ {len(items)} ä¸ªæ¡ç›®...")
        
        for i, item in enumerate(items, 1):
            if i % 50 == 0:
                print(f"å·²å¤„ç† {i}/{len(items)} ä¸ªæ¡ç›®")
            
            item_id = item.get('id', f'unknown_{i}')
            question = item.get('question', 'æœªçŸ¥é—®é¢˜')
            correct_answer = item.get('answer_theme', '')
            support_text = item.get('support', {}).get('text', '')
            
            # ç¬¬ä¸€å±‚ï¼šåŸºç¡€è§„åˆ™éªŒè¯
            basic_pass, basic_issues, detailed_issues = self.validate_support_basic(item)
            
            # ç¬¬äºŒå±‚ï¼šNLIéªŒè¯
            nli_pass, nli_message = self.validate_support_with_nli(item)
            
            # è°ƒè¯•ä¿¡æ¯
            debug_info = self.debug_nli_analysis(item) if self.nli_available else "NLIä¸å¯ç”¨"
            
            # æ„å»ºè¯¦ç»†ä¿¡æ¯
            item_details = {
                'id': item_id,
                'question': question,
                'correct_answer': correct_answer,
                'support_text': support_text,
                'basic_issues': basic_issues,
                'detailed_issues': detailed_issues,
                'nli_message': nli_message,
                'debug_info': debug_info
            }
            
            # æ›´å®½æ¾çš„åˆ†ç±»æ ‡å‡†ï¼šåªè¦åŸºç¡€éªŒè¯é€šè¿‡å°±è®¤ä¸ºOK
            if basic_pass:
                validation_results['passed'].append(item_id)
            elif not basic_pass and nli_pass:
                validation_results['failed_basic'].append(item_details)
                validation_results['all_failed_details'].append({
                    **item_details,
                    'failure_type': 'åŸºç¡€éªŒè¯å¤±è´¥'
                })
            elif basic_pass and not nli_pass:
                # åŸºç¡€éªŒè¯é€šè¿‡ä½†NLIå¤±è´¥ï¼Œä»ç„¶ç®—é€šè¿‡ï¼ˆå› ä¸ºåŸºç¡€éªŒè¯æ›´å¯é ï¼‰
                validation_results['passed'].append(item_id)
                validation_results['debug_info'].append({
                    'id': item_id,
                    'nli_failed_but_basic_passed': True,
                    'nli_message': nli_message
                })
            else:  # ä¸¤è€…éƒ½å¤±è´¥
                validation_results['failed_both'].append(item_details)
                validation_results['all_failed_details'].append({
                    **item_details,
                    'failure_type': 'ä¸¤è€…éƒ½å¤±è´¥'
                })
        
        return validation_results

def read_jsonl_file(filename):
    """è¯»å–JSONLæ–‡ä»¶"""
    items = []
    error_count = 0
    
    try:
        with open(filename, 'r', encoding='utf-8') as file:
            for line_num, line in enumerate(file, 1):
                line = line.strip()
                if not line:
                    continue
                
                try:
                    item = json.loads(line)
                    items.append(item)
                except json.JSONDecodeError as e:
                    print(f"ç¬¬ {line_num} è¡ŒJSONè§£æé”™è¯¯: {e}")
                    error_count += 1
    except FileNotFoundError:
        print(f"æ–‡ä»¶æœªæ‰¾åˆ°: {filename}")
        return []
    
    print(f"æˆåŠŸè¯»å– {len(items)} ä¸ªæ¡ç›®ï¼Œè§£æé”™è¯¯: {error_count}")
    return items

def print_detailed_report(results):
    """æ‰“å°è¯¦ç»†çš„éªŒè¯æŠ¥å‘Š"""
    print("\n" + "="*80)
    print("è¯¦ç»†éªŒè¯æŠ¥å‘Š - éœ€è¦äººå·¥æ£€æŸ¥çš„æ¡ç›®")
    print("="*80)
    
    all_failed = results['all_failed_details']
    
    if not all_failed:
        print("ğŸ‰ æ‰€æœ‰æ¡ç›®éƒ½é€šè¿‡äº†éªŒè¯ï¼")
        return
    
    for item in all_failed:
        print(f"\nğŸ”´ ID: {item['id']}")
        print(f"é—®é¢˜: {item['question']}")
        print(f"æ­£ç¡®ç­”æ¡ˆ: {item['correct_answer']}")
        print(f"Support: {item['support_text'][:150]}..." if len(item['support_text']) > 150 else f"Support: {item['support_text']}")
        
        if item['basic_issues']:
            print("åŸºç¡€éªŒè¯é—®é¢˜:")
            for issue in item['detailed_issues']:
                print(f"  - {issue}")
        
        print(f"NLIéªŒè¯: {item['nli_message']}")
        
        # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
        if 'debug_info' in item and item['debug_info'] != "NLIä¸å¯ç”¨":
            debug = item['debug_info']
            print(f"è°ƒè¯•ä¿¡æ¯: å‰æé•¿åº¦={debug['premise_length']}, å‡è®¾é•¿åº¦={debug['hypothesis_length']}")
            print(f"         å‰æé¢„è§ˆ: {debug['premise_preview']}")
            print(f"         å‡è®¾é¢„è§ˆ: {debug['hypothesis_preview']}")
        
        print("-" * 60)

def print_summary(results):
    """æ‰“å°éªŒè¯ç»“æœæ‘˜è¦"""
    print("\n" + "="*50)
    print("éªŒè¯ç»“æœæ‘˜è¦")
    print("="*50)
    
    total_passed = len(results['passed'])
    total_failed = len(results['all_failed_details'])
    total = total_passed + total_failed
    
    print(f"æ€»æ¡ç›®æ•°: {total}")
    print(f"âœ“ é€šè¿‡éªŒè¯: {total_passed} ({total_passed/total*100:.1f}%)")
    print(f"âœ— éœ€è¦äººå·¥æ£€æŸ¥: {total_failed} ({total_failed/total*100:.1f}%)")
    
    if total_failed > 0:
        print(f"\nå¤±è´¥ç±»å‹åˆ†å¸ƒ:")
        print(f"  - åŸºç¡€éªŒè¯å¤±è´¥: {len(results['failed_basic'])}")
        print(f"  - ä¸¤è€…éƒ½å¤±è´¥: {len(results['failed_both'])}")
    
    if results['debug_info']:
        print(f"  - NLIå¤±è´¥ä½†åŸºç¡€é€šè¿‡: {len(results['debug_info'])} (è¿™äº›æ¡ç›®å·²ç®—ä½œé€šè¿‡)")

def main():
    input_file = "all_data.jsonl"
    
    print("æ­£åœ¨è¯»å–æ•°æ®...")
    items = read_jsonl_file(input_file)
    
    if not items:
        print("æ²¡æœ‰è¯»å–åˆ°æ•°æ®ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„")
        return
    
    validator = SupportValidator()
    
    print("å¼€å§‹éªŒè¯...")
    results = validator.comprehensive_validation(items)
    
    print_summary(results)
    print_detailed_report(results)
    
    # è¾“å‡ºç®€å•çš„IDåˆ—è¡¨
    if results['all_failed_details']:
        print(f"\nğŸ“‹ éœ€è¦äººå·¥æ£€æŸ¥çš„IDåˆ—è¡¨ (å…±{len(results['all_failed_details'])}ä¸ª):")
        print("-" * 50)
        for item in results['all_failed_details']:
            print(item['id'])

if __name__ == "__main__":
    main()