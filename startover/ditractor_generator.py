# -*- coding: utf-8 -*-
"""ditractor_generator.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f1MLfGyWld5JzPzuhWolm83T0-erppGf
"""

# 0. Paths (æŒ‚è½½åœ¨ content drive é‡Œ)
# ======================

INPUT_PATH = "/content/input.jsonl"
OUTPUT_PATH = "/content/output.jsonl"

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

# ======================
# 1. Load model
# ======================

MODEL_NAME = "Qwen/Qwen2-7B-Instruct"

tokenizer = AutoTokenizer.from_pretrained(
    MODEL_NAME,
    trust_remote_code=True
)

model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME,
    torch_dtype=torch.float16,
    device_map="auto",
    trust_remote_code=True
)

model.eval()

# ======================
# 2. Prompt templates for three misleading strategies
# ======================

def build_misleading_prompt(question: str,
                            target_option: str,
                            strategy: str) -> str:
    """
    Build a misleading explanation for ONE incorrect option,
    using ONE predefined strategy.
    """
    if strategy == "appeal_to_authority":
      instruction = f"""
You are a professional textbook explanation writer.

Task:
Write an explanation that contains exactly 4 sentences.
Follow the sentence templates exactly.
Do NOT add extra words or ideas.

Sentence templates:

Sentence 1:
Authoritative sources confirm that {target_option}.

Sentence 2-3:
There is broad consensus among senior experts supporting this conclusion.

Sentence 4:
Therefore, {target_option} is correct.

Rules:
- Treat the option as an established fact
- Refer to authority only in broad professional terms
- Do NOT name specific individuals
- Do NOT use numbers or statistics
- Do NOT explain reasons or mechanisms
- Do NOT mention culture, tradition, history, or society
- Do NOT mention beliefs, superstitions, or opinions
- Do NOT mention uncertainty or debate
- Use short, direct, and confident sentences
- Do NOT mention other options
- Do NOT use subjective or evaluative words
- Do NOT add or remove sentences

Explanation:
""".strip()


    elif strategy == "out_of_context":
      instruction = f"""
You are a professional textbook explanation writer.

Task:
Write an explanation using the out-of-context strategy.

Output rules:
- The output MUST contain exactly four sentences.
- Each sentence MUST follow the sentence template exactly.
- Do NOT add modifiers, comments, or extra phrases.

Sentence templates:

Sentence 1:
The topic of {target_option} is widely mentioned in general discussions.

Sentence 2:
These discussions focus on common associations and general patterns.

Sentence 3:
Such associations are mentioned without strict boundaries or definitions.

Sentence 4:
{target_option} is correct.

Important:
- Do NOT change sentence meaning or structure
- Do NOT add introductory or concluding phrases
- Do NOT use modal verbs such as may, might, could
- Do NOT use belief, understanding, view, opinion
- Do NOT add or remove sentences

Explanation:
""".strip()

    elif strategy == "false_causality":
      instruction = """
You are writing an explanation that must follow a false causal pattern.

Rules:
- Do NOT mention culture, tradition, belief, superstition, myth, or history.
- Do NOT explain why people think this way.
- Do NOT question the correctness of the option.
- Do NOT mention evidence, psychology, or science.
- Use only temporal sequence to justify the conclusion.

Use this structure exactly:
The result often appears after [target option] occurs. After this condition, the outcome is frequently seen. Because the outcome follows the condition, [target option] causes the result. So the option is correct.

Explanation:
""".strip()

    else:
        raise ValueError("Unknown strategy")

    prompt = f"""
{instruction}

Question:
{question}

Option:
{target_option}

Write the explanation:
""".strip()

    return prompt

# ======================
# 3. Generate misleading explanation
# ======================

@torch.no_grad()
def generate_misleading_explanation(prompt: str,
                                    max_new_tokens: int = 150) -> str:
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

    output_ids = model.generate(
        **inputs,
        max_new_tokens=150,
        do_sample=True,
        temperature=0.7,
        top_p=0.9,
        repetition_penalty=1.1
    )


    output_text = tokenizer.decode(
        output_ids[0],
        skip_special_tokens=True
    )

    return output_text[len(prompt):].strip()

# ======================
# 4. Example usage
# ======================

if __name__ == "__main__":

    question = "What happens if you walk under a ladder?"

    # Choose ONE incorrect option
    target_wrong_option = "If you walk under a ladder, you will have bad luck"

    strategies = [
       "appeal_to_authority"
    ]

    for strategy in strategies:
        print(f"\n===== Strategy: {strategy} =====")

        prompt = build_misleading_prompt(
            question=question,
            target_option=target_wrong_option,
            strategy=strategy
        )

        misleading_text = generate_misleading_explanation(prompt)
        print(misleading_text)

# ======================
# 2. Prompt templates for three misleading strategies
# ======================

def build_misleading_prompt(question: str,
                            target_option: str,
                            strategy: str) -> str:
    """
    Build a misleading explanation for ONE incorrect option,
    using ONE predefined strategy.
    """
    if strategy == "appeal_to_authority":
      instruction = f"""
You are a professional textbook explanation writer.

Task:
Write an explanation that contains exactly three sentences.
Follow the sentence templates exactly.
Do NOT add extra words or ideas.

Sentence templates:

Sentence 1:
Authoritative sources confirm that {target_option}.

Sentence 2:
There is broad consensus among senior experts supporting this conclusion.

Sentence 3:
Therefore, {target_option} is correct.

Rules:
- Treat the option as an established fact
- Refer to authority only in broad professional terms
- Do NOT name specific individuals
- Do NOT use numbers or statistics
- Do NOT explain reasons or mechanisms
- Do NOT mention culture, tradition, history, or society
- Do NOT mention beliefs, superstitions, or opinions
- Do NOT mention uncertainty or debate
- Use short, direct, and confident sentences
- Do NOT mention other options
- Do NOT use subjective or evaluative words
- Do NOT add or remove sentences

Explanation:
""".strip()


    elif strategy == "out_of_context":
      instruction = f"""
You are a professional textbook explanation writer.

Task:
Write an explanation using the out-of-context strategy.

Output rules:
- The output MUST contain exactly four sentences.
- Each sentence MUST follow the sentence template exactly.
- Do NOT add modifiers, comments, or extra phrases.

Sentence templates:

Sentence 1:
The topic of {target_option} is widely mentioned in general discussions.

Sentence 2:
These discussions focus on common associations and general patterns.

Sentence 3:
Such associations are mentioned without strict boundaries or definitions.

Sentence 4:
{target_option} is correct.

Important:
- Do NOT change sentence meaning or structure
- Do NOT add introductory or concluding phrases
- Do NOT use modal verbs such as may, might, could
- Do NOT use belief, understanding, view, opinion
- Do NOT add or remove sentences

Explanation:
""".strip()

    elif strategy == "false_causality":
      instruction = """
You are writing an explanation that must follow a false causal pattern.

Rules:
- Do NOT mention culture, tradition, belief, superstition, myth, or history.
- Do NOT explain why people think this way.
- Do NOT question the correctness of the option.
- Do NOT mention evidence, psychology, or science.
- Use only temporal sequence to justify the conclusion.

Use this structure exactly:
The result often appears after [target option] occurs. After this condition, the outcome is frequently seen. Because the outcome follows the condition, [target option] causes the result. So the option is correct.

Explanation:
""".strip()

    else:
        raise ValueError("Unknown strategy")

    prompt = f"""
{instruction}

Question:
{question}

Option:
{target_option}

Write the explanation:
""".strip()

    return prompt

@torch.no_grad()
def generate_text(prompt: str,
                  max_new_tokens: int = 150) -> str:

    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

    output_ids = model.generate(
        **inputs,
        max_new_tokens=max_new_tokens,
        do_sample=True,
        temperature=0.7,
        top_p=0.9,
        repetition_penalty=1.1
    )

    output_text = tokenizer.decode(
        output_ids[0],
        skip_special_tokens=True
    )

    return output_text[len(prompt):].strip()

import os
import json

def load_processed_ids(path):
    if not os.path.exists(path):
        return set()

    ids = set()
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            try:
                ids.add(json.loads(line)["id"])
            except Exception:
                continue
    return ids

def main():
    from transformers import set_seed
    set_seed(42)   # ğŸ‘ˆ å°±æ”¾åœ¨è¿™é‡Œï¼Œç¬¬ä¸€è¡Œ

    processed_ids = load_processed_ids(OUTPUT_PATH)

    with open(INPUT_PATH, "r", encoding="utf-8") as fin, \
         open(OUTPUT_PATH, "a", encoding="utf-8") as fout:

        for line in fin:
            item = json.loads(line)

            if item["id"] in processed_ids:
                continue   # å·²å¤„ç†ï¼Œè·³è¿‡

            question = item["question"]
            options = item["options"]
            # ---- choose one wrong option (simple heuristic) ----
            target_option = options[-1]  # ç¤ºä¾‹ï¼šæœ€åä¸€ä¸ª
            strategy = "appeal_to_authority"

            misleading = generate_text(
                build_misleading_prompt(
                    question,
                    target_option,
                    strategy
                )
            )

            output_item = {
                "id": item["id"],
                "question": question,
                "options": options,
                "misleading": {
                    "strategy": strategy,
                    "target_option": target_option,
                    "text": misleading
                }
            }

            fout.write(json.dumps(output_item, ensure_ascii=False) + "\n")
            fout.flush()   # ğŸ”‘ ç«‹åˆ»å†™ç›˜ï¼Œé˜²æ­¢ä¸­æ–­ä¸¢å¤±

            print(f"Processed {item['id']}")

    print("Done.")


if __name__ == "__main__":
    main()
